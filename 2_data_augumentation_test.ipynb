{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Final Integrador Visión por Computadora II - CEIA - FIUBA - Cohorte 16\n",
    "\n",
    "Alumnos: Fabricio Lopretto (a1616) y Santiago José Olaciregui (a1611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance de Clases\n",
    "\n",
    "Objetivo: Se busca conocer si las clases (números de las cartas) se encuentran balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa librerías necesarias\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de la notebook\n",
    "script_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de imágenes por clase:\n",
      "Clase 0: 1255 imágenes\n",
      "Clase 1: 1220 imágenes\n",
      "Clase 2: 1258 imágenes\n",
      "Clase 3: 1267 imágenes\n",
      "Clase 4: 1273 imágenes\n",
      "Clase 5: 1262 imágenes\n",
      "Clase 6: 1280 imágenes\n",
      "Clase 7: 1289 imágenes\n",
      "Clase 8: 1313 imágenes\n",
      "Clase 9: 1220 imágenes\n",
      "Clase 10: 1322 imágenes\n",
      "Clase 11: 1208 imágenes\n",
      "Clase 12: 1241 imágenes\n",
      "Clase 13: 1210 imágenes\n",
      "Clase 14: 1267 imágenes\n",
      "********************\n",
      "Clase 7: 1289 imágenes (6.83%)\n",
      "Clase 8: 1313 imágenes (6.95%)\n",
      "Clase 12: 1241 imágenes (6.57%)\n",
      "Clase 9: 1220 imágenes (6.46%)\n",
      "Clase 10: 1322 imágenes (7.00%)\n",
      "Clase 14: 1267 imágenes (6.71%)\n",
      "Clase 4: 1273 imágenes (6.74%)\n",
      "Clase 2: 1258 imágenes (6.66%)\n",
      "Clase 1: 1220 imágenes (6.46%)\n",
      "Clase 3: 1267 imágenes (6.71%)\n",
      "Clase 13: 1210 imágenes (6.41%)\n",
      "Clase 5: 1262 imágenes (6.68%)\n",
      "Clase 6: 1280 imágenes (6.78%)\n",
      "Clase 0: 1255 imágenes (6.65%)\n",
      "Clase 11: 1208 imágenes (6.40%)\n"
     ]
    }
   ],
   "source": [
    "# Directorio de los archivos de anotaciones (.txt) del conjunto train\n",
    "annotations_folder_train = script_path + '/data/data_original/train/labels/'\n",
    "\n",
    "# Lista para almacenar todas las clases detectadas en los archivos\n",
    "all_classes = []\n",
    "\n",
    "# Recorre todos los archivos de etiquetas en el directorio\n",
    "for filename in os.listdir(annotations_folder_train):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(annotations_folder_train, filename)\n",
    "        \n",
    "        # Abre el archivo de anotación y lee las líneas\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # Cada línea empieza con el número de clase\n",
    "                class_id = line.split()[0]\n",
    "                all_classes.append(int(class_id))\n",
    "\n",
    "# Contar la cantidad de instancias de cada clase\n",
    "class_counts = Counter(all_classes)\n",
    "\n",
    "# Mostrar la cantidad de imágenes por clase\n",
    "print(\"Cantidad de imágenes por clase:\")\n",
    "for class_id in range(15):\n",
    "    print(f\"Clase {class_id}: {class_counts[class_id]} imágenes\")\n",
    "\n",
    "print('*'*20)\n",
    "\n",
    "# Calcular y mostrar si hay desbalance de clases\n",
    "total_images = sum(class_counts.values())\n",
    "for class_id, count in class_counts.items():\n",
    "    percentage = (count / total_images) * 100\n",
    "    print(f\"Clase {class_id}: {count} imágenes ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "\n",
    "Indagar la necesidad y experimentos para aumentar la cantidad de datos, realizando las siguientes operaciones:\n",
    "\n",
    "**Transformaciones geométricas:**\n",
    "\n",
    "1. Rotación: Girar la imagen en ángulos aleatorios.\n",
    "2. Escalado: Aumentar o reducir el tamaño de la imagen.\n",
    "3. Translación: Desplazar la imagen horizontal o verticalmente.\n",
    "\n",
    "**Background augmentation:**\n",
    "\n",
    "4. Background generation: Enseñar al modelo a distinguir entre fondo y objeto.\n",
    "\n",
    "**Transformaciones de ruido:**\n",
    "\n",
    "5. Ruido gaussiano: Añadir ruido aleatorio a la imagen.\n",
    "6. Ruido sal y pimienta: Introducir píxeles aleatorios en la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Rotación\n",
    "\n",
    "*Notas*:\n",
    "1. Toma un recorte de 104x104 píxeles de la esquina superior izquierda de la imagen original y lo repita como mosaico para llenar una imagen de fondo de 416x416 píxeles.\n",
    "2. Luego, insertaremos el objeto rotado de forma aleatoria sobre el fondo de mosaico.\n",
    "3. Para cada rotación (90, 180, 270 grados), el script guarda la imagen con el objeto rotado sobre el fondo de mosaico en el directorio de salida y el nuevo etiquetado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Las imágenes y anotaciones rotadas se han guardado.\n"
     ]
    }
   ],
   "source": [
    "input_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "input_annotations = script_path + '/data/data_procesada/train_mask_background/train/labels/'\n",
    "output_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "output_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "\n",
    "# Tamaño de la imagen de salida y del recorte\n",
    "output_size = (416, 416)\n",
    "patch_size = (104, 104)\n",
    "\n",
    "# Función para generar un fondo de mosaico y superponer el objeto rotado\n",
    "def generate_mosaic_background(image):\n",
    "    \"\"\"\n",
    "    Extrae un recorte de 104x104 píxeles de la esquina superior izquierda de la imagen original.\n",
    "    Crea una nueva imagen de 416x416 píxeles y llena la imagen con el recorte en forma de mosaico.\n",
    "    \"\"\"\n",
    "    # Extraer un recorte de 104x104 de la esquina superior izquierda\n",
    "    patch = image[:patch_size[1], :patch_size[0]]\n",
    "    \n",
    "    # Crear una imagen de fondo vacía de 416x416 píxeles\n",
    "    background_image = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "    \n",
    "    # Repetir el recorte en mosaico para llenar la imagen de fondo\n",
    "    for y in range(0, output_size[1], patch_size[1]):\n",
    "        for x in range(0, output_size[0], patch_size[0]):\n",
    "            end_x = min(x + patch_size[0], output_size[0])\n",
    "            end_y = min(y + patch_size[1], output_size[1])\n",
    "            background_image[y:end_y, x:end_x] = patch[:end_y - y, :end_x - x]\n",
    "    \n",
    "    return background_image\n",
    "\n",
    "# Función para rotar el objeto y colocarlo sobre el fondo de mosaico\n",
    "def rotate_object(image, bbox, angle):\n",
    "    \"\"\"\n",
    "    Rota el objeto extraído de la imagen en el ángulo especificado (90, 180 o 270 grados).\n",
    "    Genera un fondo de mosaico usando generate_mosaic_background.\n",
    "    Calcula la posición y dimensiones normalizadas del objeto rotado para actualizar la anotación y lo coloca encima del fondo de mosaico.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    x_center, y_center, bbox_width, bbox_height = bbox\n",
    "    \n",
    "    # Convertir las dimensiones del bounding box a píxeles\n",
    "    bbox_width_px = int(bbox_width * width)\n",
    "    bbox_height_px = int(bbox_height * height)\n",
    "    \n",
    "    # Extraer el recorte del objeto\n",
    "    x1 = max(0, int(x_center * width) - bbox_width_px // 2)\n",
    "    y1 = max(0, int(y_center * height) - bbox_height_px // 2)\n",
    "    x2 = x1 + bbox_width_px\n",
    "    y2 = y1 + bbox_height_px\n",
    "    object_crop = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Rotar el recorte del objeto\n",
    "    if angle == 90:\n",
    "        rotated_object = cv2.rotate(object_crop, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif angle == 180:\n",
    "        rotated_object = cv2.rotate(object_crop, cv2.ROTATE_180)\n",
    "    elif angle == 270:\n",
    "        rotated_object = cv2.rotate(object_crop, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    else:\n",
    "        rotated_object = object_crop  # Sin rotación (caso no debería suceder)\n",
    "    \n",
    "    # Generar el fondo de mosaico\n",
    "    background_image = generate_mosaic_background(image)\n",
    "    \n",
    "    # Calcular el tamaño del recorte rotado\n",
    "    rotated_height, rotated_width = rotated_object.shape[:2]\n",
    "    \n",
    "    # Calcular nuevas coordenadas para centrar el objeto rotado en el fondo de mosaico\n",
    "    new_x1 = max(0, int(x_center * output_size[0]) - rotated_width // 2)\n",
    "    new_y1 = max(0, int(y_center * output_size[1]) - rotated_height // 2)\n",
    "    new_x2 = new_x1 + rotated_width\n",
    "    new_y2 = new_y1 + rotated_height\n",
    "    \n",
    "    # Insertar el objeto rotado sobre el fondo de mosaico\n",
    "    background_image[new_y1:new_y2, new_x1:new_x2] = rotated_object\n",
    "    \n",
    "    # Calcular nuevas dimensiones normalizadas del bounding box rotado\n",
    "    new_bbox_width = rotated_width / output_size[0]\n",
    "    new_bbox_height = rotated_height / output_size[1]\n",
    "    \n",
    "    return background_image, (x_center, y_center, new_bbox_width, new_bbox_height)\n",
    "\n",
    "# Procesar cada imagen y su anotación\n",
    "for filename in os.listdir(input_images):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_images, filename)\n",
    "        annotation_path = os.path.join(input_annotations, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "        \n",
    "        # Cargar la imagen y la anotación\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            bbox = [float(p) for p in parts[1:]]\n",
    "            \n",
    "            # Crear imágenes con el objeto rotado en 90, 180 y 270 grados\n",
    "            for angle in [90, 180, 270]:\n",
    "                modified_image, new_bbox = rotate_object(image, bbox, angle)\n",
    "                \n",
    "                # Guardar la nueva imagen\n",
    "                angle_suffix = f\"rot_{angle}\"\n",
    "                new_image_name = f\"{filename.split('.')[0]}_{angle_suffix}.jpg\"\n",
    "                new_image_path = os.path.join(output_images, new_image_name)\n",
    "                cv2.imwrite(new_image_path, modified_image)\n",
    "                \n",
    "                # Guardar la nueva anotación\n",
    "                new_annotation_name = f\"{filename.split('.')[0]}_{angle_suffix}.txt\"\n",
    "                new_annotation_path = os.path.join(output_annotations, new_annotation_name)\n",
    "                \n",
    "                with open(new_annotation_path, 'w') as f_out:\n",
    "                    f_out.write(f\"{class_id} {new_bbox[0]} {new_bbox[1]} {new_bbox[2]} {new_bbox[3]}\\n\")\n",
    "\n",
    "print(\"Proceso completado. Las imágenes y anotaciones rotadas con fondo de mosaico se han guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Escalado\n",
    "\n",
    "Se generan imagenes con objetos ampliados o reducidos a partir de las imagenes preexistentes.\n",
    "\n",
    "*Notas:*\n",
    "1. Toma un cuadrado de 104x104 píxeles de la esquina superior izquierda de la imagen original y lo replicará en mosaico para crear un fondo de 416x416 píxeles.\n",
    "2. El objeto escalado se colocará sobre este fondo de mosaico.\n",
    "3. Para cada factor de escala (scale_factors), el script guarda la imagen con el objeto redimensionado sobre el fondo de mosaico en el directorio de salida y su etiquetado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Las imágenes y anotaciones ajustadas se han guardado.\n"
     ]
    }
   ],
   "source": [
    "# Directorios de entrada y salida\n",
    "input_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "input_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "output_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "output_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "\n",
    "# Dimensiones de la imagen de salida y del recorte\n",
    "output_size = (416, 416)\n",
    "patch_size = (104, 104)\n",
    "\n",
    "# Factor de escalado para aumentar o reducir el tamaño del objeto\n",
    "scale_factors = [0.5, 0.75, 1.25, 1.5]\n",
    "\n",
    "# Función para generar un fondo de mosaico\n",
    "def generate_mosaic_background(image):\n",
    "    \"\"\"\n",
    "    Extrae un recorte de 104x104 píxeles de la esquina superior izquierda de la imagen original.\n",
    "    Crea una nueva imagen de fondo de 416x416 píxeles y llena la imagen con el recorte en forma de mosaico.\n",
    "    \"\"\"\n",
    "    # Extraer un recorte de 104x104 de la esquina superior izquierda\n",
    "    patch = image[:patch_size[1], :patch_size[0]]\n",
    "    \n",
    "    # Crear una imagen de fondo vacía de 416x416 píxeles\n",
    "    background_image = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "    \n",
    "    # Repetir el recorte en mosaico para llenar la imagen de fondo\n",
    "    for y in range(0, output_size[1], patch_size[1]):\n",
    "        for x in range(0, output_size[0], patch_size[0]):\n",
    "            end_x = min(x + patch_size[0], output_size[0])\n",
    "            end_y = min(y + patch_size[1], output_size[1])\n",
    "            background_image[y:end_y, x:end_x] = patch[:end_y - y, :end_x - x]\n",
    "    \n",
    "    return background_image\n",
    "\n",
    "# Función para escalar el objeto y colocarlo sobre el fondo de mosaico\n",
    "def resize_object(image, bbox, scale_factor):\n",
    "    \"\"\"\n",
    "    Redimensiona el objeto extraído de la imagen en función del scale_factor.\n",
    "    Genera un fondo de mosaico usando generate_mosaic_background.\n",
    "    Calcula la posición y dimensiones normalizadas del objeto redimensionado\n",
    "    para actualizar la anotación y lo coloca encima del fondo de mosaico.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    x_center, y_center, bbox_width, bbox_height = bbox\n",
    "    \n",
    "    # Convertir las dimensiones del bounding box a píxeles\n",
    "    bbox_width_px = int(bbox_width * width)\n",
    "    bbox_height_px = int(bbox_height * height)\n",
    "    \n",
    "    # Calcular las nuevas dimensiones del bounding box\n",
    "    new_bbox_width_px = int(bbox_width_px * scale_factor)\n",
    "    new_bbox_height_px = int(bbox_height_px * scale_factor)\n",
    "    \n",
    "    # Asegurarse de que el nuevo tamaño no exceda los límites de la imagen\n",
    "    if new_bbox_width_px > output_size[0] or new_bbox_height_px > output_size[1]:\n",
    "        new_bbox_width_px = min(new_bbox_width_px, output_size[0])\n",
    "        new_bbox_height_px = min(new_bbox_height_px, output_size[1])\n",
    "    \n",
    "    # Extraer el recorte del objeto original\n",
    "    x1 = max(0, int(x_center * width) - bbox_width_px // 2)\n",
    "    y1 = max(0, int(y_center * height) - bbox_height_px // 2)\n",
    "    x2 = x1 + bbox_width_px\n",
    "    y2 = y1 + bbox_height_px\n",
    "    object_crop = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Redimensionar el recorte del objeto\n",
    "    resized_object = cv2.resize(object_crop, (new_bbox_width_px, new_bbox_height_px), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Generar el fondo de mosaico\n",
    "    background_image = generate_mosaic_background(image)\n",
    "    \n",
    "    # Calcular las coordenadas del nuevo centro en píxeles\n",
    "    new_x1 = max(0, int(x_center * output_size[0]) - new_bbox_width_px // 2)\n",
    "    new_y1 = max(0, int(y_center * output_size[1]) - new_bbox_height_px // 2)\n",
    "    new_x2 = new_x1 + new_bbox_width_px\n",
    "    new_y2 = new_y1 + new_bbox_height_px\n",
    "    \n",
    "    # Colocar el objeto redimensionado en el fondo de mosaico\n",
    "    background_image[new_y1:new_y2, new_x1:new_x2] = resized_object\n",
    "    \n",
    "    # Calcular las nuevas dimensiones normalizadas\n",
    "    new_bbox_width = new_bbox_width_px / output_size[0]\n",
    "    new_bbox_height = new_bbox_height_px / output_size[1]\n",
    "    \n",
    "    return background_image, (x_center, y_center, new_bbox_width, new_bbox_height)\n",
    "\n",
    "# Procesar cada imagen y su anotación\n",
    "for filename in os.listdir(input_images):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_images, filename)\n",
    "        annotation_path = os.path.join(input_annotations, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "        \n",
    "        # Cargar la imagen y la anotación\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            bbox = [float(p) for p in parts[1:]]\n",
    "            \n",
    "            # Crear imágenes con el objeto en diferentes tamaños\n",
    "            for scale_factor in scale_factors:\n",
    "                modified_image, new_bbox = resize_object(image, bbox, scale_factor)\n",
    "                \n",
    "                # Guardar la nueva imagen\n",
    "                scale_suffix = f\"scale_{scale_factor}\"\n",
    "                new_image_name = f\"{filename.split('.')[0]}_{scale_suffix}.jpg\"\n",
    "                new_image_path = os.path.join(output_images, new_image_name)\n",
    "                cv2.imwrite(new_image_path, modified_image)\n",
    "                \n",
    "                # Guardar la nueva anotación\n",
    "                new_annotation_name = f\"{filename.split('.')[0]}_{scale_suffix}.txt\"\n",
    "                new_annotation_path = os.path.join(output_annotations, new_annotation_name)\n",
    "                \n",
    "                with open(new_annotation_path, 'w') as f_out:\n",
    "                    f_out.write(f\"{class_id} {new_bbox[0]} {new_bbox[1]} {new_bbox[2]} {new_bbox[3]}\\n\")\n",
    "\n",
    "print(\"Proceso completado. Las imágenes y anotaciones ajustadas se han guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Traslación\n",
    "\n",
    "*Notas:*\n",
    "\n",
    "1. Toma un recorte de 104x104 píxeles de la esquina superior izquierda de la imagen original y lo replicará como un mosaico para crear un fondo de 416x416 píxeles.\n",
    "2. El objeto reubicado se coloca sobre este fondo de mosaico.\n",
    "3. Para cada posición especificada, genera una nueva imagen con el objeto reposicionado de forma aleatoria sobre el fondo de mosaico.\n",
    "4. Guarda las imágenes modificadas y sus anotaciones actualizadas en los directorios de salida y su etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Las imágenes y anotaciones modificadas se han guardado.\n"
     ]
    }
   ],
   "source": [
    "# Rutas a los directorios de imágenes y anotaciones\n",
    "input_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "input_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "output_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "output_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "\n",
    "# Dimensiones de la imagen de salida y del recorte\n",
    "output_size = (416, 416)\n",
    "patch_size = (104, 104)\n",
    "\n",
    "# Función para generar un fondo de mosaico\n",
    "def generate_mosaic_background(image):\n",
    "    # Extraer un recorte de 104x104 de la esquina superior izquierda\n",
    "    patch = image[:patch_size[1], :patch_size[0]]\n",
    "    \n",
    "    # Crear una imagen de fondo vacía de 416x416 píxeles\n",
    "    background_image = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "    \n",
    "    # Repetir el recorte en mosaico para llenar la imagen de fondo\n",
    "    for y in range(0, output_size[1], patch_size[1]):\n",
    "        for x in range(0, output_size[0], patch_size[0]):\n",
    "            end_x = min(x + patch_size[0], output_size[0])\n",
    "            end_y = min(y + patch_size[1], output_size[1])\n",
    "            background_image[y:end_y, x:end_x] = patch[:end_y - y, :end_x - x]\n",
    "    \n",
    "    return background_image\n",
    "\n",
    "# Función para reubicar el objeto y colocarlo sobre el fondo de mosaico\n",
    "def relocate_object(image, bbox):\n",
    "    \"\"\"\n",
    "    Calcula el recorte del objeto de acuerdo con su bounding box.\n",
    "    Genera un fondo de mosaico utilizando generate_mosaic_background.\n",
    "    Coloca el objeto en una de las cuatro posiciones aleatorias\n",
    "    en el fondo de mosaico.\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    x_center, y_center, bbox_width, bbox_height = bbox\n",
    "    \n",
    "    # Convertir las dimensiones del bounding box a píxeles\n",
    "    bbox_width_px = int(bbox_width * width)\n",
    "    bbox_height_px = int(bbox_height * height)\n",
    "    x_center_px = int(x_center * width)\n",
    "    y_center_px = int(y_center * height)\n",
    "    \n",
    "    # Extraer el recorte del objeto\n",
    "    x1 = max(0, x_center_px - bbox_width_px // 2)\n",
    "    y1 = max(0, y_center_px - bbox_height_px // 2)\n",
    "    x2 = min(width, x_center_px + bbox_width_px // 2)\n",
    "    y2 = min(height, y_center_px + bbox_height_px // 2)\n",
    "    \n",
    "    object_crop = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Generar el fondo de mosaico\n",
    "    background = generate_mosaic_background(image)\n",
    "    \n",
    "    # Generar cuatro posiciones aleatorias para el centro del objeto\n",
    "    random_positions = []\n",
    "    for _ in range(4):\n",
    "        new_x_center_px = random.randint(bbox_width_px // 2, output_size[0] - bbox_width_px // 2)\n",
    "        new_y_center_px = random.randint(bbox_height_px // 2, output_size[1] - bbox_height_px // 2)\n",
    "        random_positions.append((new_x_center_px, new_y_center_px))\n",
    "    \n",
    "    # Procesar cada posición aleatoria\n",
    "    modified_images_and_bboxes = []\n",
    "    for i, (new_x_center_px, new_y_center_px) in enumerate(random_positions):\n",
    "        # Calcular las nuevas coordenadas de recorte del objeto en la imagen de fondo\n",
    "        new_x1 = max(0, new_x_center_px - bbox_width_px // 2)\n",
    "        new_y1 = max(0, new_y_center_px - bbox_height_px // 2)\n",
    "        \n",
    "        # Colocar el recorte del objeto en la posición aleatoria sobre el fondo de mosaico\n",
    "        modified_background = background.copy()\n",
    "        modified_background[new_y1:new_y1 + object_crop.shape[0], new_x1:new_x1 + object_crop.shape[1]] = object_crop\n",
    "        \n",
    "        # Normalizar las coordenadas del centro del objeto en la imagen de fondo\n",
    "        new_x_center = new_x_center_px / output_size[0]\n",
    "        new_y_center = new_y_center_px / output_size[1]\n",
    "        \n",
    "        modified_images_and_bboxes.append((modified_background, (new_x_center, new_y_center, bbox_width, bbox_height)))\n",
    "    \n",
    "    return modified_images_and_bboxes\n",
    "\n",
    "# Procesar cada imagen y su anotación\n",
    "for filename in os.listdir(input_images):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_images, filename)\n",
    "        annotation_path = os.path.join(input_annotations, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "\n",
    "        # Cargar la imagen y la anotación\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        with open(annotation_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            bbox = [float(p) for p in parts[1:]]\n",
    "            \n",
    "            # Crear cuatro nuevas imágenes con el objeto en posiciones aleatorias\n",
    "            modified_images_and_bboxes = relocate_object(image, bbox)\n",
    "            for i, (modified_image, new_bbox) in enumerate(modified_images_and_bboxes):\n",
    "                \n",
    "                # Guardar la nueva imagen\n",
    "                new_image_name = f\"{filename.split('.')[0]}_random_{i}.jpg\"\n",
    "                new_image_path = os.path.join(output_images, new_image_name)\n",
    "                cv2.imwrite(new_image_path, modified_image)\n",
    "                \n",
    "                # Guardar la nueva anotación\n",
    "                new_annotation_name = f\"{filename.split('.')[0]}_random_{i}.txt\"\n",
    "                new_annotation_path = os.path.join(output_annotations, new_annotation_name)\n",
    "                \n",
    "                with open(new_annotation_path, 'w') as f_out:\n",
    "                    f_out.write(f\"{class_id} {new_bbox[0]} {new_bbox[1]} {new_bbox[2]} {new_bbox[3]}\\n\")\n",
    "\n",
    "print(\"Proceso completado. Las imágenes y anotaciones modificadas se han guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Background generation: Se generan imagenes sin objetos de ninguna clase.\n",
    "\n",
    "*Notas:*\n",
    "\n",
    "Asegurarnos de que las imágenes de fondo tengan las mismas dimensiones que las originales, podemos modificar el script para generar una imagen de fondo completa. La solución implica seleccionar áreas aleatorias sin objetos y copiarlas en diferentes partes de la imagen original hasta llenarla completamente. De esta forma, obtenemos una imagen del mismo tamaño que la original sin ningún objeto visible.\n",
    "\n",
    "1. Para cada imagen en el dataset, el script genera una versión de fondo con el mismo tamaño y la guarda en el directorio de salida.\n",
    "2. Asigna un nombre a la nueva imagen que indica que es de fondo (_background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Las imágenes de fondo en mosaico se han guardado.\n"
     ]
    }
   ],
   "source": [
    "# Rutas a los directorios de imágenes y anotaciones\n",
    "input_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "input_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "output_background = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "\n",
    "# Dimensiones de la imagen de salida y del recorte\n",
    "output_size = (416, 416)\n",
    "patch_size = (104, 104)\n",
    "\n",
    "# Función para generar una imagen de fondo de tamaño fijo a partir de un recorte de 104x104 de la esquina superior izquierda\n",
    "def generate_tiled_background(image):\n",
    "    # Extraer el recorte de la esquina superior izquierda\n",
    "    patch = image[:patch_size[1], :patch_size[0]]\n",
    "    \n",
    "    # Crear una imagen de fondo vacía del tamaño deseado\n",
    "    background_image = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "    \n",
    "    # Repetir el recorte en mosaico para llenar la imagen de fondo\n",
    "    for y in range(0, output_size[1], patch_size[1]):\n",
    "        for x in range(0, output_size[0], patch_size[0]):\n",
    "            # Pegar el recorte en la posición actual, ajustando si se sale de los límites\n",
    "            end_x = min(x + patch_size[0], output_size[0])\n",
    "            end_y = min(y + patch_size[1], output_size[1])\n",
    "            background_image[y:end_y, x:end_x] = patch[:end_y - y, :end_x - x]\n",
    "    \n",
    "    return background_image\n",
    "\n",
    "# Genera la misma cantidad de fondos solos que imagenes con on¡bjetos para balancear\n",
    "for i in range(52):\n",
    "    # Procesar cada imagen\n",
    "    for filename in os.listdir(input_images):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(input_images, filename)\n",
    "            \n",
    "            # Cargar la imagen\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # Generar la imagen de fondo\n",
    "            background_image = generate_tiled_background(image)\n",
    "            \n",
    "            # Guardar la imagen de fondo\n",
    "            new_image_name = f\"{filename.split('.')[0]}_background.jpg\"\n",
    "            new_image_path = os.path.join(output_background, new_image_name)\n",
    "            cv2.imwrite(new_image_path, background_image)\n",
    "\n",
    "print(\"Proceso completado. Las imágenes de fondo en mosaico se han guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Generación de ruido\n",
    "\n",
    "*Nota:*\n",
    "\n",
    "Agrega ruido Gaussiano o ruido \"sal y pimienta\" de forma aleatoria a cada imagen en tu dataset y guarda las imágenes con ruido aplicando uno de estos dos tipos de ruido en cada imagen.\n",
    "\n",
    "1. Para cada imagen, el script elige aleatoriamente entre ruido gaussiano y ruido \"sal y pimienta\".\n",
    "2. Guardado de las imágenes y anotaciones. La imagen con ruido se guarda en el directorio de salida con un sufijo que indica el tipo de ruido aplicado (_gaussian o _salt_pepper).\n",
    "3. Las anotaciones se copian sin cambios al nuevo nombre, ya que el ruido no afecta la ubicación o tamaño del objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Las imágenes con ruido y anotaciones se han guardado.\n"
     ]
    }
   ],
   "source": [
    "# Rutas a los directorios de imágenes y anotaciones\n",
    "input_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "input_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "output_images = script_path + '/data/data_procesada/train_mask_background/images/'\n",
    "output_annotations = script_path + '/data/data_procesada/train_mask_background/labels/'\n",
    "\n",
    "# Función para agregar ruido Gaussiano\n",
    "def add_gaussian_noise(image, mean=0, sigma=25):\n",
    "    \"\"\"\n",
    "    Agrega ruido gaussiano con una media y desviación estándar configurables.\n",
    "    Se aplica usando una distribución normal, y la imagen resultante se limita a valores entre 0 y 255.\n",
    "    \"\"\"\n",
    "    gaussian_noise = np.random.normal(mean, sigma, image.shape).astype(np.float32)\n",
    "    noisy_image = cv2.add(image.astype(np.float32), gaussian_noise)\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Función para agregar ruido Sal y Pimienta\n",
    "def add_salt_and_pepper_noise(image, salt_prob=0.01, pepper_prob=0.01):\n",
    "    \"\"\"\n",
    "    Agrega ruido \"sal y pimienta\".\n",
    "    La \"sal\" (blanco) y la \"pimienta\" (negro) se aplican en proporciones\n",
    "    aleatorias de píxeles definidos por salt_prob y pepper_prob.\n",
    "    \"\"\"\n",
    "    noisy_image = np.copy(image)\n",
    "    # Sal (blanco)\n",
    "    num_salt = np.ceil(salt_prob * image.size)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape[:2]]\n",
    "    noisy_image[coords[0], coords[1]] = 255\n",
    "\n",
    "    # Pimienta (negro)\n",
    "    num_pepper = np.ceil(pepper_prob * image.size)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape[:2]]\n",
    "    noisy_image[coords[0], coords[1]] = 0\n",
    "    return noisy_image\n",
    "\n",
    "# Procesar cada imagen y su anotación\n",
    "for filename in os.listdir(input_images):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_images, filename)\n",
    "        annotation_path = os.path.join(input_annotations, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "        \n",
    "        # Copiar la anotación original al directorio de salida\n",
    "        shutil.copy(annotation_path, output_annotations)\n",
    "        \n",
    "        # Cargar la imagen\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        # Decidir aleatoriamente el tipo de ruido\n",
    "        noise_type = random.choice(['gaussian', 'salt_and_pepper'])\n",
    "        \n",
    "        # Agregar el ruido seleccionado a la imagen\n",
    "        if noise_type == 'gaussian':\n",
    "            noisy_image = add_gaussian_noise(image)\n",
    "            noise_suffix = 'gaussian'\n",
    "        else:\n",
    "            noisy_image = add_salt_and_pepper_noise(image)\n",
    "            noise_suffix = 'salt_pepper'\n",
    "        \n",
    "        # Guardar la imagen con ruido\n",
    "        new_image_name = f\"{filename.split('.')[0]}_{noise_suffix}.jpg\"\n",
    "        new_image_path = os.path.join(output_images, new_image_name)\n",
    "        cv2.imwrite(new_image_path, noisy_image)\n",
    "        \n",
    "        # Copiar el archivo de anotación original con el nuevo nombre\n",
    "        new_annotation_name = f\"{filename.split('.')[0]}_{noise_suffix}.txt\"\n",
    "        new_annotation_path = os.path.join(output_annotations, new_annotation_name)\n",
    "        shutil.copy(annotation_path, new_annotation_path)\n",
    "\n",
    "print(\"Proceso completado. Las imágenes con ruido y anotaciones se han guardado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones:\n",
    "\n",
    "Al analizar el balance de clases, resultó que el conjunto de datos se encuentra balanceado por defecto. Con lo cual no es necesario aumentar la cantidad de imagenes con objetos de una clase en particular. Lo único que se consideró necesario fue generar imagenes solo con fondo, dado que en el conjunto de imagenes utilizado, todas las imagenes contienen una carta (y por ende objeto).\n",
    "\n",
    "Por otro lado, se evaluo incorporar imagenes aplicando transformaciones geométricas y ruido a las existentes. Al realizar esto, el tamaño del conjunto de datos resultó inmanejable para los recursos disponibles. Por este motivo, se decidió utilizar arquitecturas como YOLO que disponen de un *pipeline* con *data augumentation* durante el entrenamiento por lotes. En la correspondiente notebook, se explora esta opción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
